{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2faf4d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Trey Tuscai and Gordon Doore\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4052dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 22:12:51.074953: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-12 22:13:02.621560: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047510",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<!-- # Project 3 | Word Embeddings and Sentiment Analysis -->\n",
    "# Project 3 | Word Embeddings\n",
    "\n",
    "The goal of this project is to gain insight about the representations learned by neural networks — how do they encode the training data internally? We will transition to training neural network on text data — specifically on tens of thousands of real Amazon reviews of fashion products (e.g. clothes, shoes, etc.). \n",
    "\n",
    "<!-- Next week, you will train a CNN to predict whether the reviews are positive or negative, a task in the field natural language processing (NLP) called **sentiment analysis**. -->\n",
    "\n",
    "<!-- #### Week 1: Word Embeddings of Amazon Fashion Reviews -->\n",
    "\n",
    "This notebook focuses on building the Amazon Fashion Reviews text preprocessing pipeline as well as analyzing and visualizing how a neural network learns to encode words from the reviews. You will train a **Continuous Bag of Words (CBOW)** (word2vec) neural network commonly used in the field of natural language processing (NLP) on text from IMDb user movie reviews. The network attempts to predict a **target word** (a missing word from a passage of text) from the surrounding **context words** (the words surrounding the target word in a sentence). After implementing and training the network, you will extract the weights to obtain $H$ dimensional **word embedding** vectors for English words that appeared in the Amazon reviews to analyze and visualize. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025704",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 1: Preprocessing Amazon Fashion Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e917",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1a. Download and inspect first several few Amazon reviews\n",
    "\n",
    "Download the Amazon Fashion dataset (`Amazon_Fashion.jsonl`) from the project website and store it in the `data` subfolder of your working directory. These Amazon reviews were curated by [the McAuley lab in 2023](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023).\n",
    "\n",
    "In the cell below, use the provided `load_reviews_and_ratings` function in `amazon_reviews.py` to load in the 1st five reviews and ratings. Print these first five reviews and clearly indicate the star rating for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2431ce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from amazon_reviews import load_reviews_and_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9153af",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "Rating: 5.0 stars\n",
      "Text: I think this locket is really pretty. The inside back is a solid silver depression and the front is a dome that is not solid (knotted). You could use it to store a small photo, lock of hair, etc but I use it when I need to carry medication with me. Closes securely. High quality & very pretty.\n",
      "\n",
      "Review 2:\n",
      "Rating: 5.0 stars\n",
      "Text: Great\n",
      "\n",
      "Review 3:\n",
      "Rating: 2.0 stars\n",
      "Text: One of the stones fell out within the first 2 weeks of wearing it. Stones smaller than expected.\n",
      "\n",
      "Review 4:\n",
      "Rating: 1.0 stars\n",
      "Text: Crappy socks. Money wasted. Bought to wear with my tieks. Don’t stay on feet well.\n",
      "\n",
      "Review 5:\n",
      "Rating: 5.0 stars\n",
      "Text: I LOVE these glasses!  They fit perfectly over my regular, rectangular glasses that I always have to wear in order to see.  I really appreciate having these pretty and stylish and sturdy sunglasses to wear over my glasses.  I'll buy these again and again whenever I need a new pair, which hopefully won't be too soon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews, ratings = load_reviews_and_ratings(N_reviews=5)\n",
    "\n",
    "for i, (review, rating) in enumerate(zip(reviews, ratings)):\n",
    "    print(f\"Review {i+1}:\")\n",
    "    print(f\"Rating: {rating:.1f} stars\")\n",
    "    print(f\"Text: {review}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1b. Make the corpus\n",
    "\n",
    "We will use a \"flat\"/1D list of sentences across the reviews as our **corpus**. That is, we REMOVE information about which review a sentence came from in the corpus. However, we will eventually need this information in order to determine whether a review is positive/negative so we maintain a separate list that indicates to which review a given sentence belongs. For example: Sent 0 belongs to review 0, Sent 1 belongs to review 0, Sent 2 belongs to review 1, etc.\n",
    "\n",
    "To make sure we have enough context words in sentences, we prune sentences that are too short. We also prune sentences that are too long.\n",
    "\n",
    "Implement `make_corpus` in `amazon_reviews.py` to create the corpus of sentences and review ID associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f8fa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from amazon_reviews import make_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8d93",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in the corpus (after pruning short sentences/identifying words): 185.\n",
      "There should be 185 sentences\n",
      "The first few sent ratings are: [5. 5. 5. 5. 5. 2. 2. 1. 1. 1.] and should be [5. 5. 5. 5. 5. 2. 2. 1. 1. 1.]\n",
      "The last few sent ratings are: [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.] and should be [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "The first few review_ids are: [0 0 0 0 0 2 2 3 3 3] and should be [0 0 0 0 0 2 2 3 3 3]\n",
      "The last few review_ids are: [49 49 49 49 49 49 49 49 49 49] and should be [49 49 49 49 49 49 49 49 49 49]\n"
     ]
    }
   ],
   "source": [
    "corpus, sentence_ratings, review_ids = make_corpus(N_reviews=50)\n",
    "print(f'Number of sentences in the corpus (after pruning short sentences/identifying words): {len(corpus)}.')\n",
    "print('There should be 185 sentences')\n",
    "assert len(corpus) == len(sentence_ratings)\n",
    "assert len(corpus) == len(review_ids)\n",
    "print(f'The first few sent ratings are: {sentence_ratings[:10]} and should be [5. 5. 5. 5. 5. 2. 2. 1. 1. 1.]')\n",
    "print(f'The last few sent ratings are: {sentence_ratings[-10:]} and should be [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]')\n",
    "print(f'The first few review_ids are: {review_ids[:10]} and should be [0 0 0 0 0 2 2 3 3 3]')\n",
    "print(f'The last few review_ids are: {review_ids[-10:]} and should be [49 49 49 49 49 49 49 49 49 49]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb50b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1c. Make the vocabulary\n",
    "\n",
    "We will be training a **word-level model**, so our tokens will be single words. Implement `find_unique_words` to form the **vocabulary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab9c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from amazon_reviews import find_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f23387",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words:\n",
      " ['I', 'love', 'CS444', 'deep', 'learning', 'CS', 'Colby']\n",
      "unique words should be:\n",
      " ['I', 'love', 'CS444', 'deep', 'learning', 'CS', 'Colby']\n",
      "Number of unique words in the 50 reviews: 677 and should be 677.\n"
     ]
    }
   ],
   "source": [
    "test_text = [['I', 'love', 'CS444'],\n",
    "             ['I', 'love', 'deep', 'learning'],\n",
    "             ['I', 'love', 'CS'],\n",
    "             ['I', 'love', 'Colby']]\n",
    "unique = find_unique_words(test_text)\n",
    "print('unique words:\\n', unique)\n",
    "print(\"unique words should be:\\n ['I', 'love', 'CS444', 'deep', 'learning', 'CS', 'Colby']\")\n",
    "\n",
    "unique_words_corpus = find_unique_words(corpus)\n",
    "print(f'Number of unique words in the 50 reviews: {len(unique_words_corpus)} and should be 677.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39adba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1d. Mapping words to indices and back\n",
    "\n",
    "While our corpus is currently made of word strings we clearly cannot plug these in as inputs to a neural network! We need to convert these word features to numbers first. For the specific CBOW word2vec neural network we are implementing, we *could plug in each word represented as a one-hot vector. To determine the location of the 1 in each vector, we use the word's position in the vocabulary. \n",
    "\n",
    "Implement and test `make_word2ind_mapping` to convert a string word to its position index in the vocab and `make_ind2word_mapping` to perform the reverse — looking up a string word based on its int index.\n",
    "\n",
    "*For efficiency, we won't *actually* plug in one-hot vectors into CBOW. We'll use the int indices instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebf00",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from amazon_reviews import make_word2ind_mapping, make_ind2word_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c42f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the test text, your word2ind mapping is:\n",
      "{'I': 0, 'love': 1, 'CS444': 2, 'deep': 3, 'learning': 4, 'CS': 5, 'Colby': 6}\n",
      "and it should be\n",
      "{'I': 0, 'love': 1, 'CS444': 2, 'deep': 3, 'learning': 4, 'CS': 5, 'Colby': 6}\n",
      "\n",
      "The reverse ind2word mapping is:\n",
      "{0: 'I', 1: 'love', 2: 'CS444', 3: 'deep', 4: 'learning', 5: 'CS', 6: 'Colby'}\n",
      "and it should be\n",
      "{0: 'I', 1: 'love', 2: 'CS444', 3: 'deep', 4: 'learning', 5: 'CS', 6: 'Colby'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'For the test text, your word2ind mapping is:\\n{make_word2ind_mapping(unique)}')\n",
    "print('and it should be')\n",
    "print(\"{'I': 0, 'love': 1, 'CS444': 2, 'deep': 3, 'learning': 4, 'CS': 5, 'Colby': 6}\")\n",
    "print()\n",
    "print(f'The reverse ind2word mapping is:\\n{make_ind2word_mapping(unique)}')\n",
    "print('and it should be')\n",
    "print(\"{0: 'I', 1: 'love', 2: 'CS444', 3: 'deep', 4: 'learning', 5: 'CS', 6: 'Colby'}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b372",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Amazon text, your word2ind mapping has :\n",
      "677 entries.\n",
      "and it should have\n",
      "677 entries.\n",
      "{'I': 0, 'love': 1, 'CS444': 2, 'deep': 3, 'learning': 4, 'CS': 5, 'Colby': 6}\n",
      "\n",
      "For the Amazon text, the reverse ind2word mapping has:\n",
      "677 entries.\n",
      "and it should have\n",
      "677 entries.\n"
     ]
    }
   ],
   "source": [
    "print(f'For the Amazon text, your word2ind mapping has :\\n{len(make_word2ind_mapping(unique_words_corpus))} entries.')\n",
    "print('and it should have\\n677 entries.')\n",
    "print(\"{'I': 0, 'love': 1, 'CS444': 2, 'deep': 3, 'learning': 4, 'CS': 5, 'Colby': 6}\")\n",
    "print()\n",
    "print(f'For the Amazon text, the reverse ind2word mapping has:\\n{len(make_ind2word_mapping(unique_words_corpus))} entries.')\n",
    "print('and it should have\\n677 entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1e. Use the corpus to form context and target word tensors\n",
    "\n",
    "Together, these make up the data samples and labels on which we will train the CBOW network. To form these tensors, we step through the corpus and identify each word as a target word and surrounding words within the **context window** as context words. To handle the fact that there are an irregular number of context words around each target words, we code samples as individual *pairs* of context and target words and we duplicate target words as needed. For example, for the target word `love` in `I love CS444`, we code add the target word entries of `1, 1` and add context word entries of `0, 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba73ed",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from amazon_reviews import make_target_context_word_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb201",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test: context window of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e89e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the test text, the int-coded target words are:\n",
      "[0 1 1 2 0 1 1 3 3 4 0 1 1 5 0 1 1 6]\n",
      "and they should be:\n",
      "[0 1 1 2 0 1 1 3 3 4 0 1 1 5 0 1 1 6]\n",
      "For the test text, the int-coded context words are:\n",
      "[1 0 2 1 1 0 3 1 4 3 1 0 5 1 1 0 6 1]\n",
      "and they should be:\n",
      "[1 0 2 1 1 0 3 1 4 3 1 0 5 1 1 0 6 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 20:51:55.889181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20601 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "test_target_words_int, test_context_words_int = make_target_context_word_lists(test_text,\n",
    "                                                                               make_word2ind_mapping(unique),\n",
    "                                                                               context_win_sz=1)\n",
    "print(f'For the test text, the int-coded target words are:\\n{test_target_words_int.numpy()}')\n",
    "print('and they should be:')\n",
    "print('[0 1 1 2 0 1 1 3 3 4 0 1 1 5 0 1 1 6]')\n",
    "print(f'For the test text, the int-coded context words are:\\n{test_context_words_int.numpy()}')\n",
    "print('and they should be:')\n",
    "print('[1 0 2 1 1 0 3 1 4 3 1 0 5 1 1 0 6 1]')\n",
    "# Make sure we have the correct dtype since these will eventually need to serve as indices\n",
    "assert test_target_words_int.dtype == tf.int32\n",
    "assert test_context_words_int.dtype == tf.int32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d7d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test: Default context window of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b14e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the test text, the int-coded target words are:\n",
      "[0 0 1 1 2 2 0 0 1 1 1 3 3 3 4 4 0 0 1 1 5 5 0 0 1 1 6 6]\n",
      "and they should be:\n",
      "[0 0 1 1 2 2 0 0 1 1 1 3 3 3 4 4 0 0 1 1 5 5 0 0 1 1 6 6]\n",
      "For the test text, the int-coded context words are:\n",
      "[1 2 0 2 0 1 1 3 0 3 4 0 1 4 1 3 1 5 0 5 0 1 1 6 0 6 0 1]\n",
      "and they should be:\n",
      "[1 2 0 2 0 1 1 3 0 3 4 0 1 4 1 3 1 5 0 5 0 1 1 6 0 6 0 1]\n"
     ]
    }
   ],
   "source": [
    "test_target_words_int, test_context_words_int = make_target_context_word_lists(test_text,\n",
    "                                                                               make_word2ind_mapping(unique))\n",
    "print(f'For the test text, the int-coded target words are:\\n{test_target_words_int.numpy()}')\n",
    "print('and they should be:')\n",
    "print('[0 0 1 1 2 2 0 0 1 1 1 3 3 3 4 4 0 0 1 1 5 5 0 0 1 1 6 6]')\n",
    "print(f'For the test text, the int-coded context words are:\\n{test_context_words_int.numpy()}')\n",
    "print('and they should be:')\n",
    "print('[1 2 0 2 0 1 1 3 0 3 4 0 1 4 1 3 1 5 0 5 0 1 1 6 0 6 0 1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453067",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test: Amazon reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e292a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the test text, there are 6930 int-coded target words and there should be 6930.\n",
      "For the test text, there are 6930 int-coded target words and there should be 6930.\n"
     ]
    }
   ],
   "source": [
    "am_target_words_int, am_context_words_int = make_target_context_word_lists(corpus,\n",
    "                                                                           make_word2ind_mapping(unique_words_corpus))\n",
    "print(f'For the test text, there are {len(am_target_words_int)} int-coded target words and there should be 6930.')\n",
    "print(f'For the test text, there are {len(am_context_words_int)} int-coded target words and there should be 6930.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab75e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1f. Function to automate obtaining training samples and labels\n",
    "\n",
    "Write `get_dataset_word2vec` to to streamline the process of going from the data file to getting the target and context word tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bdce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from amazon_reviews import get_dataset_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5cb93",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of target words in actual Amazon corpus: 5434338. There should be 5434338.\n",
      "Number of context words in actual Amazon corpus: 5434338. There should be 5434338.\n",
      "Vocab size in actual Amazon corpus: 21905. It should be 21905.\n"
     ]
    }
   ],
   "source": [
    "targets_int, contexts_int, vocab = get_dataset_word2vec(N_reviews=40000)\n",
    "print(f'Number of target words in actual Amazon corpus: {len(targets_int)}. There should be 5434338.')\n",
    "print(f'Number of context words in actual Amazon corpus: {len(contexts_int)}. There should be 5434338.')\n",
    "print(f'Vocab size in actual Amazon corpus: {len(vocab)}. It should be 21905.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd986",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 2: Build and train CBOW on Amazon Fashion Reviews\n",
    "\n",
    "Now that we have the Amazon data in an appropriate format, let's develop the CBOW neural network. It should take far less time to develop this net due to its simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2a. Copy over your deep learning library from Project 2\n",
    "\n",
    "Files to include are: `layers.py`, `block.py`, `network.py`, `tf_util.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d89",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2b. Create the `DenseEmbedding` layer\n",
    "\n",
    "This is the only new layer for CBOW, which itself is essentially just a `Dense` layer, but its inputs are used to *index* rather than *multiply* its weights. Implement the `DenseEmbedding` layer in `cbow_layers.py` then test your work below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1668",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from cbow_layers import DenseEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd6c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `DenseEmbedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20d056",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of wts/bias is (10, 5)/(5,) and they should be (10, 5)/(5,)\n",
      "The netActs from forward pass:\n",
      "[[-0.1744 -0.5512 -0.1061 -0.3297  0.3191]\n",
      " [-0.1547 -0.2417 -0.328  -0.3959  0.0067]\n",
      " [ 0.1275 -0.3441 -0.02    0.4227  0.2251]]\n",
      "and they should be:\n",
      "[[-0.1744 -0.5512 -0.1061 -0.3297  0.3191]\n",
      " [-0.1547 -0.2417 -0.328  -0.3959  0.0067]\n",
      " [ 0.1275 -0.3441 -0.02    0.4227  0.2251]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "test_embed = DenseEmbedding('TestEmbedLayer', units=5)\n",
    "tf.random.set_seed(1)\n",
    "test_M = 10\n",
    "test_embed(tf.random.uniform(shape=(1, test_M)))\n",
    "print(f'Shape of wts/bias is {test_embed.get_wts().shape}/{test_embed.get_b().shape} and they should be (10, 5)/(5,)')\n",
    "test_inds = tf.constant([2, 1, 0], dtype=tf.int32)\n",
    "test_acts = test_embed(test_inds)\n",
    "print(f'The netActs from forward pass:\\n{test_acts.numpy()}')\n",
    "print('and they should be:')\n",
    "print('''[[-0.1744 -0.5512 -0.1061 -0.3297  0.3191]\n",
    " [-0.1547 -0.2417 -0.328  -0.3959  0.0067]\n",
    " [ 0.1275 -0.3441 -0.02    0.4227  0.2251]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2c. Build CBOW architecture and implement forward pass\n",
    "\n",
    "The CBOW network has the following structure:\n",
    "\n",
    "Input → DenseEmbedding → Dense\n",
    "\n",
    "Both the input and output layer have `vocab_sz` units. The output layer uses regular softmax activation.\n",
    "\n",
    "Implement the following methods in the `CBOW` class in `cbow.py`:\n",
    "- constructor\n",
    "- `__call__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd81db",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from cbow import CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadcd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `CBOW` forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f2855",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 5]\n",
      "Dense layer output(Hidden) shape: [1, 3]\n",
      "---------------------------------------------------------------------------\n",
      "The CBOW output layer netActs from the test indices are:\n",
      "[[[0.1759 0.3235 0.0784 0.1804 0.2418]\n",
      "  [0.1438 0.1019 0.2473 0.3665 0.1406]\n",
      "  [0.2514 0.2696 0.1495 0.1182 0.2113]\n",
      "  [0.261  0.1628 0.2505 0.1626 0.1631]]]\n",
      "and they should be:\n",
      "[[[0.1759 0.3235 0.0784 0.1804 0.2418]\n",
      "  [0.1438 0.1019 0.2473 0.3665 0.1406]\n",
      "  [0.2514 0.2696 0.1495 0.1182 0.2113]\n",
      "  [0.261  0.1628 0.2505 0.1626 0.1631]]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "test_cbow = CBOW(C=5, input_feats_shape=(5,), embedding_dim=3)\n",
    "test_cbow.compile()\n",
    "test_inds = tf.constant([[1, 2, 3, 0]], dtype=tf.int32)\n",
    "test_acts = test_cbow(test_inds)\n",
    "print(f'The CBOW output layer netActs from the test indices are:\\n{test_acts.numpy()}')\n",
    "print('and they should be:')\n",
    "print('''[[[0.1759 0.3235 0.0784 0.1804 0.2418]\n",
    "  [0.1438 0.1019 0.2473 0.3665 0.1406]\n",
    "  [0.2514 0.2696 0.1495 0.1182 0.2113]\n",
    "  [0.261  0.1628 0.2505 0.1626 0.1631]]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The compile summary from the cell above should look like:\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 5]\n",
    "Dense layer output(Hidden) shape: [1, 3]\n",
    "---------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0669",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2d. Implement CBOW `fit`\n",
    "\n",
    "Implement the CBOW `fit` method. This is a large-scale simplification of your existing `fit` method, since there is no validation set and no early stopping of any kind! I suggest copy-pasting your `DeepNetwork` fit method and paring down from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9a0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: Amazon dev set\n",
    "\n",
    "Test out your `fit` method on a dev set created from the 1st 100 Amazon Fashion samples. Train a CBOW network with default hyperparameters for `100` epochs. The loss should drop from ~7.2 and stabilize to ~3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e97b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 1356]\n",
      "Dense layer output(Hidden) shape: [1, 96]\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 7.5365\n",
      "Epoch 1/100 took 1.2998 seconds\n",
      "Epoch 2: Training Loss = 7.2571\n",
      "Epoch 2/100 took 0.0207 seconds\n",
      "Epoch 3: Training Loss = 6.9806\n",
      "Epoch 3/100 took 0.0192 seconds\n",
      "Epoch 4: Training Loss = 6.7496\n",
      "Epoch 4/100 took 0.0180 seconds\n",
      "Epoch 5: Training Loss = 6.5194\n",
      "Epoch 5/100 took 0.0175 seconds\n",
      "Epoch 6: Training Loss = 6.2940\n",
      "Epoch 6/100 took 0.0177 seconds\n",
      "Epoch 7: Training Loss = 6.0992\n",
      "Epoch 7/100 took 0.0189 seconds\n",
      "Epoch 8: Training Loss = 5.8748\n",
      "Epoch 8/100 took 0.0189 seconds\n",
      "Epoch 9: Training Loss = 5.7410\n",
      "Epoch 9/100 took 0.0183 seconds\n",
      "Epoch 10: Training Loss = 5.5842\n",
      "Epoch 10/100 took 0.0196 seconds\n",
      "Epoch 11: Training Loss = 5.4414\n",
      "Epoch 11/100 took 0.0179 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 5.2927\n",
      "Epoch 12/100 took 0.0182 seconds\n",
      "Epoch 13: Training Loss = 5.1891\n",
      "Epoch 13/100 took 0.0306 seconds\n",
      "Epoch 14: Training Loss = 5.0587\n",
      "Epoch 14/100 took 0.0221 seconds\n",
      "Epoch 15: Training Loss = 4.9617\n",
      "Epoch 15/100 took 0.0182 seconds\n",
      "Epoch 16: Training Loss = 4.8612\n",
      "Epoch 16/100 took 0.0177 seconds\n",
      "Epoch 17: Training Loss = 4.7910\n",
      "Epoch 17/100 took 0.0173 seconds\n",
      "Epoch 18: Training Loss = 4.6813\n",
      "Epoch 18/100 took 0.0180 seconds\n",
      "Epoch 19: Training Loss = 4.6232\n",
      "Epoch 19/100 took 0.0180 seconds\n",
      "Epoch 20: Training Loss = 4.5403\n",
      "Epoch 20/100 took 0.0178 seconds\n",
      "Epoch 21: Training Loss = 4.5010\n",
      "Epoch 21/100 took 0.0176 seconds\n",
      "Epoch 22: Training Loss = 4.4103\n",
      "Epoch 22/100 took 0.0179 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 4.3637\n",
      "Epoch 23/100 took 0.0189 seconds\n",
      "Epoch 24: Training Loss = 4.2961\n",
      "Epoch 24/100 took 0.0176 seconds\n",
      "Epoch 25: Training Loss = 4.2871\n",
      "Epoch 25/100 took 0.0173 seconds\n",
      "Epoch 26: Training Loss = 4.2166\n",
      "Epoch 26/100 took 0.0170 seconds\n",
      "Epoch 27: Training Loss = 4.1909\n",
      "Epoch 27/100 took 0.0173 seconds\n",
      "Epoch 28: Training Loss = 4.1264\n",
      "Epoch 28/100 took 0.0182 seconds\n",
      "Epoch 29: Training Loss = 4.1455\n",
      "Epoch 29/100 took 0.0210 seconds\n",
      "Epoch 30: Training Loss = 4.0923\n",
      "Epoch 30/100 took 0.0194 seconds\n",
      "Epoch 31: Training Loss = 4.0396\n",
      "Epoch 31/100 took 0.0185 seconds\n",
      "Epoch 32: Training Loss = 4.0239\n",
      "Epoch 32/100 took 0.0177 seconds\n",
      "Epoch 33: Training Loss = 3.9715\n",
      "Epoch 33/100 took 0.0178 seconds\n",
      "Epoch 34: Training Loss = 3.9546\n",
      "Epoch 34/100 took 0.0176 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 3.9525\n",
      "Epoch 35/100 took 0.0180 seconds\n",
      "Epoch 36: Training Loss = 3.9123\n",
      "Epoch 36/100 took 0.0180 seconds\n",
      "Epoch 37: Training Loss = 3.9245\n",
      "Epoch 37/100 took 0.0177 seconds\n",
      "Epoch 38: Training Loss = 3.8780\n",
      "Epoch 38/100 took 0.0175 seconds\n",
      "Epoch 39: Training Loss = 3.8774\n",
      "Epoch 39/100 took 0.0174 seconds\n",
      "Epoch 40: Training Loss = 3.8801\n",
      "Epoch 40/100 took 0.0173 seconds\n",
      "Epoch 41: Training Loss = 3.8279\n",
      "Epoch 41/100 took 0.0172 seconds\n",
      "Epoch 42: Training Loss = 3.8332\n",
      "Epoch 42/100 took 0.0176 seconds\n",
      "Epoch 43: Training Loss = 3.8415\n",
      "Epoch 43/100 took 0.0172 seconds\n",
      "Epoch 44: Training Loss = 3.8052\n",
      "Epoch 44/100 took 0.0176 seconds\n",
      "Epoch 45: Training Loss = 3.8003\n",
      "Epoch 45/100 took 0.0175 seconds\n",
      "Epoch 46: Training Loss = 3.7969\n",
      "Epoch 46/100 took 0.0174 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training Loss = 3.7641\n",
      "Epoch 47/100 took 0.0191 seconds\n",
      "Epoch 48: Training Loss = 3.7763\n",
      "Epoch 48/100 took 0.0180 seconds\n",
      "Epoch 49: Training Loss = 3.7353\n",
      "Epoch 49/100 took 0.0187 seconds\n",
      "Epoch 50: Training Loss = 3.7352\n",
      "Epoch 50/100 took 0.0184 seconds\n",
      "Epoch 51: Training Loss = 3.7408\n",
      "Epoch 51/100 took 0.0174 seconds\n",
      "Epoch 52: Training Loss = 3.7501\n",
      "Epoch 52/100 took 0.0177 seconds\n",
      "Epoch 53: Training Loss = 3.7165\n",
      "Epoch 53/100 took 0.0174 seconds\n",
      "Epoch 54: Training Loss = 3.7057\n",
      "Epoch 54/100 took 0.0272 seconds\n",
      "Epoch 55: Training Loss = 3.6922\n",
      "Epoch 55/100 took 0.0195 seconds\n",
      "Epoch 56: Training Loss = 3.6883\n",
      "Epoch 56/100 took 0.0176 seconds\n",
      "Epoch 57: Training Loss = 3.6938\n",
      "Epoch 57/100 took 0.0182 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Training Loss = 3.6721\n",
      "Epoch 58/100 took 0.0181 seconds\n",
      "Epoch 59: Training Loss = 3.6822\n",
      "Epoch 59/100 took 0.0177 seconds\n",
      "Epoch 60: Training Loss = 3.6724\n",
      "Epoch 60/100 took 0.0180 seconds\n",
      "Epoch 61: Training Loss = 3.6518\n",
      "Epoch 61/100 took 0.0171 seconds\n",
      "Epoch 62: Training Loss = 3.6587\n",
      "Epoch 62/100 took 0.0177 seconds\n",
      "Epoch 63: Training Loss = 3.6484\n",
      "Epoch 63/100 took 0.0180 seconds\n",
      "Epoch 64: Training Loss = 3.6502\n",
      "Epoch 64/100 took 0.0176 seconds\n",
      "Epoch 65: Training Loss = 3.6375\n",
      "Epoch 65/100 took 0.0175 seconds\n",
      "Epoch 66: Training Loss = 3.6530\n",
      "Epoch 66/100 took 0.0179 seconds\n",
      "Epoch 67: Training Loss = 3.6372\n",
      "Epoch 67/100 took 0.0175 seconds\n",
      "Epoch 68: Training Loss = 3.6440\n",
      "Epoch 68/100 took 0.0176 seconds\n",
      "Epoch 69: Training Loss = 3.6460\n",
      "Epoch 69/100 took 0.0221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Training Loss = 3.5981\n",
      "Epoch 70/100 took 0.0199 seconds\n",
      "Epoch 71: Training Loss = 3.6181\n",
      "Epoch 71/100 took 0.0195 seconds\n",
      "Epoch 72: Training Loss = 3.6046\n",
      "Epoch 72/100 took 0.0179 seconds\n",
      "Epoch 73: Training Loss = 3.6057\n",
      "Epoch 73/100 took 0.0180 seconds\n",
      "Epoch 74: Training Loss = 3.6038\n",
      "Epoch 74/100 took 0.0177 seconds\n",
      "Epoch 75: Training Loss = 3.6192\n",
      "Epoch 75/100 took 0.0182 seconds\n",
      "Epoch 76: Training Loss = 3.6138\n",
      "Epoch 76/100 took 0.0178 seconds\n",
      "Epoch 77: Training Loss = 3.6153\n",
      "Epoch 77/100 took 0.0187 seconds\n",
      "Epoch 78: Training Loss = 3.5970\n",
      "Epoch 78/100 took 0.0188 seconds\n",
      "Epoch 79: Training Loss = 3.5867\n",
      "Epoch 79/100 took 0.0179 seconds\n",
      "Epoch 80: Training Loss = 3.6030\n",
      "Epoch 80/100 took 0.0175 seconds\n",
      "Epoch 81: Training Loss = 3.5868\n",
      "Epoch 81/100 took 0.0173 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Training Loss = 3.6040\n",
      "Epoch 82/100 took 0.0186 seconds\n",
      "Epoch 83: Training Loss = 3.5908\n",
      "Epoch 83/100 took 0.0177 seconds\n",
      "Epoch 84: Training Loss = 3.5851\n",
      "Epoch 84/100 took 0.0174 seconds\n",
      "Epoch 85: Training Loss = 3.5833\n",
      "Epoch 85/100 took 0.0175 seconds\n",
      "Epoch 86: Training Loss = 3.5611\n",
      "Epoch 86/100 took 0.0172 seconds\n",
      "Epoch 87: Training Loss = 3.5925\n",
      "Epoch 87/100 took 0.0173 seconds\n",
      "Epoch 88: Training Loss = 3.5831\n",
      "Epoch 88/100 took 0.0171 seconds\n",
      "Epoch 89: Training Loss = 3.5889\n",
      "Epoch 89/100 took 0.0171 seconds\n",
      "Epoch 90: Training Loss = 3.5598\n",
      "Epoch 90/100 took 0.0170 seconds\n",
      "Epoch 91: Training Loss = 3.5647\n",
      "Epoch 91/100 took 0.0171 seconds\n",
      "Epoch 92: Training Loss = 3.5853\n",
      "Epoch 92/100 took 0.0169 seconds\n",
      "Epoch 93: Training Loss = 3.5748\n",
      "Epoch 93/100 took 0.0171 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Training Loss = 3.5729\n",
      "Epoch 94/100 took 0.0184 seconds\n",
      "Epoch 95: Training Loss = 3.5702\n",
      "Epoch 95/100 took 0.0180 seconds\n",
      "Epoch 96: Training Loss = 3.5599\n",
      "Epoch 96/100 took 0.0171 seconds\n",
      "Epoch 97: Training Loss = 3.5308\n",
      "Epoch 97/100 took 0.0170 seconds\n",
      "Epoch 98: Training Loss = 3.5635\n",
      "Epoch 98/100 took 0.0174 seconds\n",
      "Epoch 99: Training Loss = 3.5768\n",
      "Epoch 99/100 took 0.0169 seconds\n",
      "Epoch 100: Training Loss = 3.5389\n",
      "Epoch 100/100 took 0.0169 seconds\n",
      "Finished training after 100 epochs.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "target_words, context_words, vocab = get_dataset_word2vec(N_reviews=100, verbose=False)\n",
    "vocab_sz = len(vocab)\n",
    "model = CBOW(C=vocab_sz, input_feats_shape=(vocab_sz,))\n",
    "model.compile()\n",
    "train_loss_hist = model.fit(x=context_words, y=target_words, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2e. Train CBOW on the Amazon reviews\n",
    "\n",
    "In the cell below, train CBOW on the first `40,000` Amazon Fashion reviews for `35` epochs. You should use defaults for the other hyperparameters.\n",
    "\n",
    "Create a plot showing the CBOW loss history over training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "856c9c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 21905]\n",
      "Dense layer output(Hidden) shape: [1, 96]\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 6.2106\n",
      "Epoch 1/35 took 46.2235 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 5.6760\n",
      "Epoch 2/35 took 44.5787 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 5.6089\n",
      "Epoch 3/35 took 44.3493 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 5.5659\n",
      "Epoch 4/35 took 44.3641 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 5.5405\n",
      "Epoch 5/35 took 44.6764 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 5.5198\n",
      "Epoch 6/35 took 44.7797 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 5.5021\n",
      "Epoch 7/35 took 44.8112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 5.4896\n",
      "Epoch 8/35 took 44.4334 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 5.4819\n",
      "Epoch 9/35 took 44.6236 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 5.4725\n",
      "Epoch 10/35 took 44.6584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss = 5.4672\n",
      "Epoch 11/35 took 44.6550 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 5.4612\n",
      "Epoch 12/35 took 44.5319 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss = 5.4552\n",
      "Epoch 13/35 took 44.3721 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Training Loss = 5.4508\n",
      "Epoch 14/35 took 44.6614 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss = 5.4479\n",
      "Epoch 15/35 took 44.7187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 5.4434\n",
      "Epoch 16/35 took 44.8540 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training Loss = 5.4421\n",
      "Epoch 17/35 took 44.7344 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss = 5.4390\n",
      "Epoch 18/35 took 44.4234 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training Loss = 5.4371\n",
      "Epoch 19/35 took 44.6588 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 5.4328\n",
      "Epoch 20/35 took 44.6445 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Training Loss = 5.4348\n",
      "Epoch 21/35 took 44.6709 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training Loss = 5.4297\n",
      "Epoch 22/35 took 44.5098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 5.4307\n",
      "Epoch 23/35 took 44.4103 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 5.4293\n",
      "Epoch 24/35 took 44.6749 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Training Loss = 5.4265\n",
      "Epoch 25/35 took 44.6644 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training Loss = 5.4253\n",
      "Epoch 26/35 took 44.8228 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training Loss = 5.4246\n",
      "Epoch 27/35 took 44.7488 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 5.4204\n",
      "Epoch 28/35 took 44.4772 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Training Loss = 5.4204\n",
      "Epoch 29/35 took 44.6573 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training Loss = 5.4184\n",
      "Epoch 30/35 took 44.6608 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Training Loss = 5.4163\n",
      "Epoch 31/35 took 44.6483 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 5.4173\n",
      "Epoch 32/35 took 44.4805 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training Loss = 5.4174\n",
      "Epoch 33/35 took 44.4740 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training Loss = 5.4152\n",
      "Epoch 34/35 took 44.6699 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 5.4138\n",
      "Epoch 35/35 took 44.7123 seconds\n",
      "Finished training after 35 epochs.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "target_words, context_words, vocab = get_dataset_word2vec(N_reviews=40000, verbose=False)\n",
    "model = CBOW(C=len(vocab), input_feats_shape=(len(vocab),))\n",
    "model.compile()\n",
    "train_loss_hist = model.fit(x=context_words, y=target_words, epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be83ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(train_loss_hist, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('CBOW Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aeac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2f. Get and save embeddings\n",
    "\n",
    "To prevent having to retrain the CBOW network every time you want to access or analyze the word embeddings, I am providing a method `save_embeddings` that saves the network embeddings to disk in subfolder `export` in your working directory. \n",
    "\n",
    "<!-- **You will need to save your embeddings for sentiment analysis net week.**  -->\n",
    "\n",
    "Here is how you would load the embeddings in the future after saving them:\n",
    "\n",
    "```python\n",
    "loaded_embeddings = np.load('export/embeddings.npz')\n",
    "loaded_embeddings = loaded_embeddings['embeddings']\n",
    "```\n",
    "\n",
    "The `save_embeddings` method and forthcoming analysis will require getting all the embeddings from the network (`get_all_embeddings`) or only the embedding for one specific word (`get_word_embedding`). In `cbow.py`, write these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `get_all_embeddings` and `get_word_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d47fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 3]\n",
      "Dense layer output(Hidden) shape: [1, 5]\n",
      "---------------------------------------------------------------------------\n",
      "All the embeddings are:\n",
      "[[ 0.8724  0.2442 -0.2423 -0.5982 -0.7141]\n",
      " [ 0.2715 -0.0081  0.6864  0.3479  0.3462]\n",
      " [-0.4074 -0.25    0.4582 -0.4027 -0.5542]]\n",
      "and they should be:\n",
      "[[ 0.8724  0.2442 -0.2423 -0.5982 -0.7141]\n",
      " [ 0.2715 -0.0081  0.6864  0.3479  0.3462]\n",
      " [-0.4074 -0.25    0.4582 -0.4027 -0.5542]]\n",
      "The embedding for index 1 is\n",
      "[ 0.2715 -0.0081  0.6864  0.3479  0.3462]\n",
      "and it should be:\n",
      "[ 0.2715 -0.0081  0.6864  0.3479  0.3462]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "test_net = CBOW(input_feats_shape=(3,), C=3, embedding_dim=5)\n",
    "test_net.compile()\n",
    "print('All the embeddings are:')\n",
    "print(test_net.get_all_embeddings().numpy())\n",
    "print('and they should be:')\n",
    "print('''[[ 0.8724  0.2442 -0.2423 -0.5982 -0.7141]\n",
    " [ 0.2715 -0.0081  0.6864  0.3479  0.3462]\n",
    " [-0.4074 -0.25    0.4582 -0.4027 -0.5542]]''')\n",
    "print('The embedding for index 1 is')\n",
    "print(test_net.get_word_embedding(1).numpy())\n",
    "print('and it should be:')\n",
    "print('''[ 0.2715 -0.0081  0.6864  0.3479  0.3462]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0787",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Run/adapt the following cell to save your embeddings to disk (`net` is your net trained on the reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5e17d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model.save_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cd1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 3: Visualizing word embeddings with t-SNE\n",
    "\n",
    "In this task, you will use the **cosine similarity** metric to find the words that have the most similar embedding to some query words of your choice. You will use the [t-SNE dimensionality reduction algorithm ](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) built into scikit-learn to visualize in 2D the relative positioning of the query word and words with the highest cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b042",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3a. Implement cosine similarity to get the most similar words to a query word\n",
    "\n",
    "Given a word that we are interested in, the cosine similarity will find the $k$ words that have the most similar embeddings to that of the query word.\n",
    "\n",
    "Here is a refresher on the cosine similarity equation:\n",
    "\n",
    "$$\n",
    "\\text{Cosine Similarity} = \\frac{(\\text{Wts})(\\vec{w})}{\\sqrt{\\sum_{j=1}^H (\\text{Wts}^T)_j^2} \\sqrt{\\sum_{j=1}^H w_j^2}}\n",
    "$$\n",
    "\n",
    "Where $\\text{Wts}$ are all the embeddings, $\\text{Wts}^T$ is the transpose of the embeddings, $\\vec{w}$ is the word embedding vector for the query word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "134a77",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from amazon_reviews import get_most_similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9055",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `get_most_similar_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "a97a85",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "test_word_str2int = {\n",
    "                     'Waterville': 0,\n",
    "                     'Acadia': 1,\n",
    "                     'Camden': 2,\n",
    "                     'Portland': 3,\n",
    "                     'Boothbay': 4,\n",
    "                     'Bangor': 5,\n",
    "                     'Kennebunkport': 6\n",
    "                    }\n",
    "test_word_int2str = {\n",
    "                     0: 'Waterville',\n",
    "                     1: 'Acadia',\n",
    "                     2: 'Camden',\n",
    "                     3: 'Portland',\n",
    "                     4: 'Boothbay',\n",
    "                     5: 'Bangor',\n",
    "                     6: 'Kennebunkport'\n",
    "                    }\n",
    "\n",
    "test_word_str = 'Waterville'\n",
    "tf.random.set_seed(0)\n",
    "test_embeddings = tf.random.uniform(shape=(7, 4)).numpy()\n",
    "test_top_inds, test_top_sims = get_most_similar_words(k=3,\n",
    "                                                      all_embeddings=test_embeddings,\n",
    "                                                      word_str=test_word_str,\n",
    "                                                      word_str2int=test_word_str2int)\n",
    "\n",
    "print(f'Words most similar to {test_word_str}:')\n",
    "for k0 in range(len(test_top_inds)):\n",
    "    print(f'{k0}: {test_word_int2str[test_top_inds[k0]]} (similarity={test_top_sims[k0]:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44449b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3b. Use t-SNE to perform dimensionality reduction on the embeddings.\n",
    "\n",
    "In the cell below:\n",
    "1. Use [scikit-learn's TSNE class](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) to reduce the dimensionality of the learned Amazon word embeddings down to 2D so that we will be able to visualize them in a scatter plot.\n",
    "2. Assign the original embeddings to a variable `embeddings`.\n",
    "3. Assign the 2D embeddings to a variable `word_tnse`. Make sure `embeddings` is a NumPy ndarray rather than a TF tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "a49c75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from amazon_reviews import find_unique_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "6a1ef7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13350",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3c. Create word cloud from Amazon Fashion review embeddings\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "1. Name the word string-to-int map `word2ind` and the word index int-to-string map `ind2word` for the Amazon Fashion dataset.\n",
    "2. Name the vocabulary for the Amazon Fashion dataset `vocab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "8737fa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d24",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pick a word for `query_word` (has it be in the vocab) and run the cell below to show the words with the 25 most similar embeddings as well as a scatter plot, which shows all the word embeddings but annotates the query word and the most similar words.\n",
    "\n",
    "**Note:** At least to start, pick query words among those that appear the most in the corpus. Code two cells down lists these most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "e35df7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "query_word = 'great'\n",
    "topk_word_inds, topk_cossim = get_most_similar_words(k=25,\n",
    "                                                     all_embeddings=embeddings,\n",
    "                                                     word_str=query_word,\n",
    "                                                     word_str2int=word2ind)\n",
    "\n",
    "\n",
    "word_strs = [ind2word[ind] for ind in topk_word_inds]\n",
    "\n",
    "print(f'Words most similar to {query_word}:')\n",
    "for k0 in range(len(topk_word_inds)):\n",
    "    print(f'{k0}: {ind2word[topk_word_inds[k0]]} (similarity={topk_cossim[k0]:.4f})')\n",
    "\n",
    "# Visualize word cloud — each word as (x, y) coords\n",
    "plt.figure(figsize=(40, 40))\n",
    "plt.scatter(word_tnse[:, 0], word_tnse[:, 1])\n",
    "\n",
    "max_xy = 5\n",
    "rng = np.random.default_rng(0)\n",
    "offsets = rng.uniform(low=-max_xy, high=max_xy, size=(len(word_strs), 2))\n",
    "for w in range(len(word_strs)):\n",
    "    plt.annotate(word_strs[w], (word_tnse[w, 0]+offsets[w,0], word_tnse[w, 1]+offsets[w,0]), fontsize=30)\n",
    "\n",
    "plt.title('Word Embeddings (2D t-SNE)')\n",
    "plt.xlabel('Embedding dim 1')\n",
    "plt.ylabel('Embedding dim 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2382e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Print the words that appear most often in the Amazon Fashion corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "f4ba19",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# TODO: modify variable name `corpus` to refer to your Amazon Fashion corpus\n",
    "unique_word_counts = find_unique_word_counts(corpus=corpus)\n",
    "top_k = 100\n",
    "\n",
    "print(f'Top {top_k} words (by count in corpus):')\n",
    "i = 0\n",
    "for word, count in unique_word_counts.items():\n",
    "    print(word, count)\n",
    "    i += 1\n",
    "\n",
    "    if i > top_k:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d79e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3d. Questions\n",
    "\n",
    "**Question 1:** Have some fun looking up word similarities. Which similarities do you like best / find the most interesting?\n",
    "\n",
    "**Question 2:** Do the most similar words tend to show up nearby or far from one another in the word cloud?\n",
    "\n",
    "**Question 3:** Why does the quality of the similar words improve for words that are more frequent in the corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b22e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 1:** \n",
    "\n",
    "**Answer 2:** \n",
    "\n",
    "**Answer 3:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ffcd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51ac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1. Analyze effect of embedding dimension\n",
    "\n",
    "- Systematically vary the embedding dimension. How does the embedding dimension affect the quality of similar words based on their embeddings / cosine similarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcf0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2. Amount of data\n",
    "\n",
    "How does the size of the dataset (number of reviews) affect the quality of the embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b304",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. Improve text preprocessing\n",
    "\n",
    "Try implementing and seeing how any of the following may change the quality of embeddings:\n",
    "\n",
    "**Stemming:** Currently words with different suffixes are treated the same — e.g. \"run\", \"runs\", \"running\", etc. Normalize these so they map the same word.\n",
    "\n",
    "**Remove stop words:** Remove common \"filler\" words that have little meaning — e.g. \"a\", \"the\", \"an\", etc.\n",
    "\n",
    "**Misspelled words**: There are numerous misspellings of words in the corpus. Does having them in the vocab help or hurt?\n",
    "\n",
    "If things improve/worsen, why might this be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca246f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 4. Other text dataset of your choice\n",
    "\n",
    "Obtain and preprocess a text dataset of your choice. Then either train on CBOW and visualize/analyze embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77499b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 5. Sentiment analysis\n",
    "\n",
    "(*This is a more involved/challenging extension*) Use the word embedding vectors as data samples into another neural network whose job it is to predict whether either the word or the Amazon review to which it and other words in the review belong is positive (say >3 star rating) or negative (say < 3 star rating). \n",
    "\n",
    "For predicting the sentiment of words, you can use a simple heuristic to get the +/- label for individual words: If the word belongs to more + reviews than - reviews, then the word is a + word (and vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3051",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 6. Other dimensionality reduction techniques\n",
    "\n",
    "Explore how different dimensionality reduction techniques alter the visualization/clustering of the words. *Keep in mind that many algorithms have hyperparameters and if one algorithm gives poor results, you should explore other hyperparameter values before concluding the algorithm does a poor job.*\n",
    "\n",
    "Some popular ideas:\n",
    "- PCA\n",
    "- UMAP\n",
    "- Self-organizing map (SOM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}